{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# $\\color{blue}{\\text{MADE}}$ $\\bullet$ $\\color{red}{\\text{NLP}}$ $\\bullet$ Lab 01\n",
        "### –ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å: [*–†–∞–¥–æ—Å–ª–∞–≤ –ù–µ–π—á–µ–≤*](https://ml-mipt.github.io/team.html)\n",
        "### –í—ã–ø–æ–ª–Ω–∏–ª: $\\text{–°–∞–∏—Ç –®–∞—Ä–∏–ø–æ–≤, –≥—Ä—É–ø–ø–∞ MADE-DS-22}$\n",
        "### üîÑ Unsupervised translation\n",
        "* * *"
      ],
      "metadata": {
        "id": "FM5324ERLoz6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eulvfJWl7ueY"
      },
      "source": [
        "# Lab 1\n",
        "\n",
        "\n",
        "## Part 1: Bilingual dictionary induction and unsupervised embedding-based MT (30%)\n",
        "*Note: this homework is based on materials from yandexdataschool [NLP course](https://github.com/yandexdataschool/nlp_course/). Feel free to check this awesome course if you wish to dig deeper.*\n",
        "\n",
        "*Refined by [Nikolay Karpachev](https://www.linkedin.com/in/nikolay-karpachev-b0146a104/)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV4rIjxa7uei"
      },
      "source": [
        "**In this homework** **<font color='red'>YOU</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
        "\n",
        "But even without parallel corpora this system can be good enough (hopefully), in particular for similar languages, e.g. Ukrainian and Russian. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idSYq2GU7uew"
      },
      "source": [
        "### Frament of the Swadesh list for some slavic languages\n",
        "\n",
        "The Swadesh list is a lexicostatistical stuff. It's named after American linguist Morris Swadesh and contains basic lexis. This list are used to define subgroupings of languages, its relatedness.\n",
        "\n",
        "So we can see some kind of word invariance for different Slavic languages.\n",
        "\n",
        "\n",
        "| Russian         | Belorussian              | Ukrainian               | Polish             | Czech                         | Bulgarian            |\n",
        "|-----------------|--------------------------|-------------------------|--------------------|-------------------------------|-----------------------|\n",
        "| –∂–µ–Ω—â–∏–Ω–∞         | –∂–∞–Ω—á—ã–Ω–∞, –∫–∞–±–µ—Ç–∞, –±–∞–±–∞    | –∂—ñ–Ω–∫–∞                   | kobieta            | ≈æena                          | –∂–µ–Ω–∞                  |\n",
        "| –º—É–∂—á–∏–Ω–∞         | –º—É–∂—á—ã–Ω–∞                  | —á–æ–ª–æ–≤—ñ–∫, –º—É–∂—á–∏–Ω–∞        | mƒô≈ºczyzna          | mu≈æ                           | –º—ä–∂                   |\n",
        "| —á–µ–ª–æ–≤–µ–∫         | —á–∞–ª–∞–≤–µ–∫                  | –ª—é–¥–∏–Ω–∞, —á–æ–ª–æ–≤—ñ–∫         | cz≈Çowiek           | ƒçlovƒõk                        | —á–æ–≤–µ–∫                 |\n",
        "| —Ä–µ–±—ë–Ω–æ–∫, –¥–∏—Ç—è   | –¥–∑—ñ—Ü—è, –¥–∑—ñ—Ü—ë–Ω–∞–∫, –Ω–µ–º–∞—û–ª—è | –¥–∏—Ç–∏–Ω–∞, –¥–∏—Ç—è            | dziecko            | d√≠tƒõ                          | –¥–µ—Ç–µ                  |\n",
        "| –∂–µ–Ω–∞            | –∂–æ–Ω–∫–∞                    | –¥—Ä—É–∂–∏–Ω–∞, –∂—ñ–Ω–∫–∞          | ≈ºona               | ≈æena, man≈æelka, cho≈•          | —Å—ä–ø—Ä—É–≥–∞, –∂–µ–Ω–∞         |\n",
        "| –º—É–∂             | –º—É–∂, –≥–∞—Å–ø–∞–¥–∞—Ä            | —á–æ–ª–æ–≤i–∫, –º—É–∂            | mƒÖ≈º                | mu≈æ, man≈æel, cho≈•             | —Å—ä–ø—Ä—É–≥, –º—ä–∂           |\n",
        "| –º–∞—Ç—å, –º–∞–º–∞      | –º–∞—Ü—ñ, –º–∞—Ç–∫–∞              | –º–∞—Ç–∏, –º–∞—Ç—ñ—Ä, –Ω–µ–Ω—è, –º–∞–º–∞ | matka              | matka, m√°ma, '—Å—Ç–∞—Ä.' mate≈ô    | –º–∞–π–∫–∞                 |\n",
        "| –æ—Ç–µ—Ü, —Ç—è—Ç—è      | –±–∞—Ü—å–∫–∞, —Ç–∞—Ç–∞             | –±–∞—Ç—å–∫–æ, —Ç–∞—Ç–æ, —Ç–∞—Ç—É—Å—å    | ojciec             | otec                          | –±–∞—â–∞, —Ç–∞—Ç–∫–æ           |\n",
        "| –º–Ω–æ–≥–æ           | —à–º–∞—Ç, –±–∞–≥–∞—Ç–∞             | –±–∞–≥–∞—Ç–æ                  | wiele              | mnoho, hodnƒõ                  | –º–Ω–æ–≥–æ                 |\n",
        "| –Ω–µ—Å–∫–æ–ª—å–∫–æ       | –Ω–µ–∫–∞–ª—å–∫—ñ, –∫–æ–ª—å–∫—ñ         | –¥–µ–∫—ñ–ª—å–∫–∞, –∫—ñ–ª—å–∫–∞        | kilka              | nƒõkolik, p√°r, trocha          | –Ω—è–∫–æ–ª–∫–æ               |\n",
        "| –¥—Ä—É–≥–æ–π, –∏–Ω–æ–π    | —ñ–Ω—à—ã                     | —ñ–Ω—à–∏–π                   | inny               | druh√Ω, jin√Ω                   | –¥—Ä—É–≥                  |\n",
        "| –∑–≤–µ—Ä—å, –∂–∏–≤–æ—Ç–Ω–æ–µ | –∂—ã–≤—ë–ª–∞, –∑–≤–µ—Ä, —ñ—Å—Ç–æ—Ç–∞     | —Ç–≤–∞—Ä–∏–Ω–∞, –∑–≤—ñ—Ä           | zwierzƒô            | zv√≠≈ôe                         | –∂–∏–≤–æ—Ç–Ω–æ               |\n",
        "| —Ä—ã–±–∞            | —Ä—ã–±–∞                     | —Ä–∏–±–∞                    | ryba               | ryba                          | —Ä–∏–±–∞                  |\n",
        "| –ø—Ç–∏—Ü–∞           | –ø—Ç—É—à–∫–∞                   | –ø—Ç–∞—Ö, –ø—Ç–∏—Ü—è             | ptak               | pt√°k                          | –ø—Ç–∏—Ü–∞                 |\n",
        "| —Å–æ–±–∞–∫–∞, –ø—ë—Å     | —Å–∞–±–∞–∫–∞                   | —Å–æ–±–∞–∫–∞, –ø–µ—Å             | pies               | pes                           | –∫—É—á–µ, –ø–µ—Å             |\n",
        "| –≤–æ—à—å            | –≤–æ—à                      | –≤–æ—à–∞                    | wesz               | ve≈°                           | –≤—ä—à–∫–∞                 |\n",
        "| –∑–º–µ—è, –≥–∞–¥       | –∑–º—è—è                     | –∑–º—ñ—è, –≥–∞–¥               | wƒÖ≈º                | had                           | –∑–º–∏—è                  |\n",
        "| —á–µ—Ä–≤—å, —á–µ—Ä–≤—è–∫   | —á–∞—Ä–≤—è–∫                   | —Ö—Ä–æ–±–∞–∫, —á–µ—Ä–≤'—è–∫         | robak              | ƒçerv                          | —á–µ—Ä–≤–µ–π                |\n",
        "| –¥–µ—Ä–µ–≤–æ          | –¥—Ä—ç–≤–∞                    | –¥–µ—Ä–µ–≤–æ                  | drzewo             | strom, d≈ôevo                  | –¥—ä—Ä–≤–æ                 |\n",
        "| –ª–µ—Å             | –ª–µ—Å                      | –ª—ñ—Å                     | las                | les                           | –≥–æ—Ä–∞, –ª–µ—Å             |\n",
        "| –ø–∞–ª–∫–∞           | –∫—ñ–π, –ø–∞–ª–∫–∞               | –ø–∞–ª–∏—Ü—è                  | patyk, prƒôt, pa≈Çka | h≈Øl, klacek, prut, k≈Øl, p√°lka | –ø–∞–ª–∫–∞, –ø—Ä—ä—á–∫–∞, –±–∞—Å—Ç—É–Ω |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNM3_fjr7ue2"
      },
      "source": [
        "But the context distribution of these languages demonstrates even more invariance. And we can use this fact for our for our purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLppwa527ue6"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwGoVhRA7ufP"
      },
      "source": [
        "In this notebook we're going to use pretrained word vectors - FastText (original paper - https://arxiv.org/abs/1607.04606).\n",
        "\n",
        "You can download them from the official [website](https://fasttext.cc/docs/en/crawl-vectors.html). We're going to need embeddings for Russian and Ukrainian languages."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gzip -d cc.ru.300.vec.gz\n",
        "\n",
        "!wget -nc https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.uk.300.vec.gz\n",
        "!gzip -d cc.uk.300.vec.gz"
      ],
      "metadata": {
        "id": "KV2-MpR-ugq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706ac760-94c0-45fb-af58-f9e56a2be677"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-12 10:00:12--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‚Äòcc.ru.300.vec.gz‚Äô\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  24.6MB/s    in 52s     \n",
            "\n",
            "2022-04-12 10:01:05 (24.2 MB/s) - ‚Äòcc.ru.300.vec.gz‚Äô saved [1306357571/1306357571]\n",
            "\n",
            "--2022-04-12 10:01:46--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.uk.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1257595219 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‚Äòcc.uk.300.vec.gz‚Äô\n",
            "\n",
            "cc.uk.300.vec.gz    100%[===================>]   1.17G  24.9MB/s    in 50s     \n",
            "\n",
            "2022-04-12 10:02:36 (24.1 MB/s) - ‚Äòcc.uk.300.vec.gz‚Äô saved [1257595219/1257595219]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After downloading and extracting the vectors, we should be able to load them using the [gensim](https://radimrehurek.com/gensim/) library:"
      ],
      "metadata": {
        "id": "Kwg26PKLv88U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u1JjQv_97ufT"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")\n",
        "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you've loaded the vectors, you can use the `KeyedVectors` interface to get word embeddings and/or query most similar words by embedding:"
      ],
      "metadata": {
        "id": "Sqb_XJhkMyHM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nTkXfT0W7ufk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6a528c-8140-4259-8e55-81c16541f3f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300,), array([ 0.0033, -0.0322, -0.0519, -0.0808, -0.0131], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "august_embedding = ru_emb[\"–∞–≤–≥—É—Å—Ç\"]\n",
        "august_embedding.shape, august_embedding[:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ru_emb.most_similar([august_embedding])"
      ],
      "metadata": {
        "id": "oQ2kCq-7NQPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85cf9bd3-ac7c-4847-de0d-ae2cff0cc906"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('–∞–≤–≥—É—Å—Ç', 1.0),\n",
              " ('–∏—é–ª—å', 0.9383153915405273),\n",
              " ('—Å–µ–Ω—Ç—è–±—Ä—å', 0.9240028858184814),\n",
              " ('–∏—é–Ω—å', 0.9222575426101685),\n",
              " ('–æ–∫—Ç—è–±—Ä—å', 0.9095538854598999),\n",
              " ('–Ω–æ—è–±—Ä—å', 0.8930036425590515),\n",
              " ('–∞–ø—Ä–µ–ª—å', 0.8729087114334106),\n",
              " ('–¥–µ–∫–∞–±—Ä—å', 0.8652557730674744),\n",
              " ('–º–∞—Ä—Ç', 0.8545796275138855),\n",
              " ('—Ñ–µ–≤—Ä–∞–ª—å', 0.8401416540145874)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The latter function also allows you to vary the amount of closest words via the `topn` argument:"
      ],
      "metadata": {
        "id": "t5EcMMI6pxzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ru_emb.most_similar([august_embedding], topn=3)"
      ],
      "metadata": {
        "id": "bi6AF3z0p9Oo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8209ff58-ba51-4cdf-f000-52f0963c0821"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('–∞–≤–≥—É—Å—Ç', 1.0),\n",
              " ('–∏—é–ª—å', 0.9383153915405273),\n",
              " ('—Å–µ–Ω—Ç—è–±—Ä—å', 0.9240028858184814)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another feature of `KeyedVectors` is that it allows to compute embeddings for multiple words simultaneously:"
      ],
      "metadata": {
        "id": "xw345NRXov4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ru_emb[[\"–∞–≤–≥—É—Å—Ç\", \"—Å–µ–Ω—Ç—è–±—Ä—å\"]].shape"
      ],
      "metadata": {
        "id": "86OuYeLYow0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0647f68f-63d3-4719-8068-af075e3ac2a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything above is true for the embeddings for Ukrainian language."
      ],
      "metadata": {
        "id": "3uGx5zHXQtfo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vdBA8lcg7ufs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80932b3a-c82e-45db-f13c-c352848c0dc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('—Å–µ—Ä–ø–µ–Ω—å', 0.9999999403953552),\n",
              " ('–ª–∏–ø–µ–Ω—å', 0.9096440076828003),\n",
              " ('–≤–µ—Ä–µ—Å–µ–Ω—å', 0.901697039604187),\n",
              " ('—á–µ—Ä–≤–µ–Ω—å', 0.8992519378662109),\n",
              " ('–∂–æ–≤—Ç–µ–Ω—å', 0.8810408711433411),\n",
              " ('–ª–∏—Å—Ç–æ–ø–∞–¥', 0.8787633776664734),\n",
              " ('–∫–≤—ñ—Ç–µ–Ω—å', 0.8592804670333862),\n",
              " ('–≥—Ä—É–¥–µ–Ω—å', 0.8586863279342651),\n",
              " ('—Ç—Ä–∞–≤–µ–Ω—å', 0.8408110737800598),\n",
              " ('–ª—é—Ç–∏–π', 0.8256431818008423)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "uk_emb.most_similar([uk_emb[\"—Å–µ—Ä–ø–µ–Ω—å\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='darkviolet'><i> \n",
        "‚úèÔ∏è \"c–µ—Ä–ø–µ–Ω—å\" —Å —É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—Å—è –∫–∞–∫ \"a–≤–≥—É—Å—Ç\". –í —Å–ø–∏—Å–∫–µ `most_similar` –≤–∏–¥–∏–º –¥—Ä—É–≥–∏–µ –º–µ—Å—è—Ü—ã –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–º —è–∑—ã–∫–µ.\n",
        "</i></font>"
      ],
      "metadata": {
        "id": "RNmQbOcoRt3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, russian and ukrainian embeddings were trained independently of each other. This means, that there is no obvious connection between values in embeddings for similar words in Russian and Ukrainian:"
      ],
      "metadata": {
        "id": "F1Dkka5uQ37-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_yJvcKXO7uf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8f2e04-549e-419c-9f4c-2127edf740aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Stepashka.com', 0.2757962942123413),\n",
              " ('–ñ–ò–ó–ù–ò–í–∞–¥–∏–º', 0.25203436613082886),\n",
              " ('2–î–º–∏—Ç—Ä–∏–π', 0.25048112869262695),\n",
              " ('2012–î–º–∏—Ç—Ä–∏–π', 0.24829231202602386),\n",
              " ('–í–µ–¥—É—â–∏–π-–ê–ª–µ–∫—Å–µ–π', 0.2443869560956955),\n",
              " ('–ù–µ–¥–æ–ø—É—Å—Ç–∏–º–æ—Å—Ç—å', 0.24435284733772278),\n",
              " ('2–ú–∏—Ö–∞–∏–ª', 0.23981399834156036),\n",
              " ('–ª–µ–∫—Å–µ–π', 0.23740756511688232),\n",
              " ('–∫–æ–º–ø–ª–µ–∫—Å–Ω', 0.23695150017738342),\n",
              " ('–ø–µ—Ä—Å–æ–Ω–∞–ª—å', 0.2368222028017044)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "ru_emb.most_similar([uk_emb[\"—Å–µ—Ä–ø–µ–Ω—å\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='darkviolet'><i> \n",
        "‚úèÔ∏è Embeddings –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–ª–∏—Å—å –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ, –ø–æ—ç—Ç–æ–º—É –º–µ–∂–¥—É –∏—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ –Ω–µ—Ç –Ω–∏—á–µ–≥–æ –æ–±—â–µ–≥–æ. \n",
        "</i></font>"
      ],
      "metadata": {
        "id": "6sAcSmsjSfqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation"
      ],
      "metadata": {
        "id": "Lia_h7W2qL8C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNdYAR1q7uf6"
      },
      "source": [
        "We'll build a simple translator, which will try to predict the russian embedding from the ukrainian one. For this we'll need a dataset of word pairs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "train_data_url = \"https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22s_made/homeworks/lab01_unsupervised_translation/uk_ru.train.tsv\"\n",
        "train_data = pd.read_csv(train_data_url, sep=\"\\t\", header=None)\n",
        "train_data.columns = [\"uk\", \"ru\"]\n",
        "print(f\"Train dataset size: {len(train_data)}\")\n",
        "\n",
        "test_data_url = \"https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22s_made/homeworks/lab01_unsupervised_translation/uk_ru.test.tsv\"\n",
        "test_data = pd.read_csv(test_data_url, sep=\"\\t\", header=None)\n",
        "test_data.columns = [\"uk\", \"ru\"]\n",
        "print(f\"Test dataset size: {len(test_data)}\")\n",
        "\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "Kon7ZH6wUYdN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "f343f7df-b3c7-4325-bf29-5bb51548d524"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 1927\n",
            "Test dataset size: 400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         uk          ru\n",
              "0  i–º–æ–≤—ñ—Ä–Ω–æ    –≤–µ—Ä–æ—è—Ç–Ω–æ\n",
              "1     i—Å–Ω—É—î  —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\n",
              "2     i—Å–ø–∏—Ç     —ç–∫–∑–∞–º–µ–Ω\n",
              "3     –∞–±–∏—è–∫  –∫–∞–∫-–Ω–∏–±—É–¥—å\n",
              "4       –∞–±–æ         –∏–ª–∏"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66942077-a8d7-4684-8f25-e9aee84530f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uk</th>\n",
              "      <th>ru</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i–º–æ–≤—ñ—Ä–Ω–æ</td>\n",
              "      <td>–≤–µ—Ä–æ—è—Ç–Ω–æ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i—Å–Ω—É—î</td>\n",
              "      <td>—Å—É—â–µ—Å—Ç–≤—É–µ—Ç</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i—Å–ø–∏—Ç</td>\n",
              "      <td>—ç–∫–∑–∞–º–µ–Ω</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>–∞–±–∏—è–∫</td>\n",
              "      <td>–∫–∞–∫-–Ω–∏–±—É–¥—å</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>–∞–±–æ</td>\n",
              "      <td>–∏–ª–∏</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66942077-a8d7-4684-8f25-e9aee84530f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-66942077-a8d7-4684-8f25-e9aee84530f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-66942077-a8d7-4684-8f25-e9aee84530f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our method won't work with unknown words, so let's filter them out:"
      ],
      "metadata": {
        "id": "DYoXmFPanrwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "for _, row in train_data.iterrows():\n",
        "    if row[\"uk\"] not in uk_emb or row[\"ru\"] not in ru_emb:\n",
        "        continue\n",
        "\n",
        "    rows.append(row)\n",
        "\n",
        "train_data = pd.DataFrame(rows)\n",
        "print(f\"Train dataset size: {len(train_data)}\")\n",
        "\n",
        "rows = []\n",
        "for _, row in test_data.iterrows():\n",
        "    if row[\"uk\"] not in uk_emb or row[\"ru\"] not in ru_emb:\n",
        "        continue\n",
        "\n",
        "    rows.append(row)\n",
        "\n",
        "test_data = pd.DataFrame(rows)\n",
        "print(f\"Test dataset size: {len(test_data)}\")"
      ],
      "metadata": {
        "id": "Ls4h2PrplJID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a3ccea-65ef-4068-ddb6-2c89aa7c4444"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 1880\n",
            "Test dataset size: 393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will train our model to predict embedding for the russian word from embedding of its ukrainian counterpart. For this reason we split our train and test data into ukrainian and russian words and compute corresponding embeddings to obtain `X` (ukrainian embeddings) and `y` (russian embeddings)."
      ],
      "metadata": {
        "id": "wwjYGFE7Ui0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = uk_emb[train_data[\"uk\"].values], ru_emb[train_data[\"ru\"].values]\n",
        "X_test, Y_test = uk_emb[test_data[\"uk\"].values], ru_emb[test_data[\"ru\"].values]"
      ],
      "metadata": {
        "id": "WR7v7lvFYWYy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZBBNvpz7ugQ"
      },
      "source": [
        "## Embedding space mapping (0.3 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Dhk5gL7ugS"
      },
      "source": [
        "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W \\sum_{i=1}^n\\|Wx_i - y_i\\|_2$$\n",
        "\n",
        "or\n",
        "\n",
        "$$W^*= \\arg\\min_W \\|XW^T - Y\\|_F$$\n",
        "\n",
        "where $\\|\\cdot\\|_F$ denotes Frobenius norm.\n",
        "\n",
        "> **Note:** in second formula, $W$ and $x$ seem to have switched places. This happens because the $X$ matrix is composed of objects $x_i$ in *rows* not *columns*, i.e. it is kind of composed of $x_i^T$. This means that $X \\in \\mathbb{R}^{N \\times D}$, where $N$ is the number of items and $D$ is the embedding dimensionality. The same is true for the $Y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acOjDdtL7ugY"
      },
      "source": [
        "$W^*= \\arg\\min_W \\sum_{i=1}^n\\|Wx_i - y_i\\|_2$ looks like simple multiple linear regression without bias. The `sklearn` allows you to turn off the bias in `LinearRegression` via the `fit_intercept` argument (in fact they simply call bias the intercept). So let's code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Lb-KN1be7uga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270fae7b-42d8-4d97-a53c-fded2ac093d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(fit_intercept=False)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "mapping = LinearRegression(fit_intercept=False) # turned off the bias\n",
        "mapping.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7tqJwoY7ugf"
      },
      "source": [
        "Let's take a look at neigbours of the vector of word _\"—Å–µ—Ä–ø–µ–Ω—å\"_ (_\"–∞–≤–≥—É—Å—Ç\"_ in Russian) after linear transform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "31SrFSbn7ugi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31fd8dd8-5675-4fe0-a241-3fb56ded45d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('–∞–ø—Ä–µ–ª—å', 0.8531432747840881),\n",
              " ('–∏—é–Ω—å', 0.8402522802352905),\n",
              " ('–º–∞—Ä—Ç', 0.8385884165763855),\n",
              " ('—Å–µ–Ω—Ç—è–±—Ä—å', 0.8331484794616699),\n",
              " ('—Ñ–µ–≤—Ä–∞–ª—å', 0.8311208486557007),\n",
              " ('–æ–∫—Ç—è–±—Ä—å', 0.8278019428253174),\n",
              " ('–Ω–æ—è–±—Ä—å', 0.8243728280067444),\n",
              " ('–∏—é–ª—å', 0.8229618072509766),\n",
              " ('–∞–≤–≥—É—Å—Ç', 0.8112280368804932),\n",
              " ('—è–Ω–≤–∞—Ä—å', 0.8022986650466919)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "august = mapping.predict(uk_emb[\"—Å–µ—Ä–ø–µ–Ω—å\"].reshape(1, -1))\n",
        "ru_emb.most_similar(august)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okSkjk597ugo"
      },
      "source": [
        "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2uY6Y9B7ugt"
      },
      "source": [
        "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in russian embedding space)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zptuho8LAfIE"
      },
      "outputs": [],
      "source": [
        "def precision(pairs, mapped_vectors, topn=1):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
        "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
        "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
        "    :returns:\n",
        "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
        "    \"\"\"\n",
        "    assert len(pairs) == len(mapped_vectors)\n",
        "    total = len(pairs)\n",
        "    correct = 0\n",
        "    for i in range(total):\n",
        "        pair = pairs[i]\n",
        "        predicted_vector = mapped_vectors[i]\n",
        "        similar_words = ru_emb.most_similar(predicted_vector.reshape(1, -1), topn=topn)\n",
        "        similar_words = [word for word, _ in similar_words]\n",
        "        if pair[1] in similar_words:\n",
        "            correct += 1\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "duhj9hpv7ugy"
      },
      "outputs": [],
      "source": [
        "assert precision([(\"—Å–µ—Ä–ø–µ–Ω—å\", \"–∞–≤–≥—É—Å—Ç\")], august, topn=5) == 0.0\n",
        "assert precision([(\"—Å–µ—Ä–ø–µ–Ω—å\", \"–∞–≤–≥—É—Å—Ç\")], august, topn=9) == 1.0\n",
        "assert precision([(\"—Å–µ—Ä–ø–µ–Ω—å\", \"–∞–≤–≥—É—Å—Ç\")], august, topn=10) == 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that our `precision` function accepts lists of pairs of words, whereas we have dataframes. However, it is not a problem: we can get a list (actually, numpy array) of pairs via the `values` property."
      ],
      "metadata": {
        "id": "z5A9tWtnuFx3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0-iyd5gP7ug5"
      },
      "outputs": [],
      "source": [
        "assert precision(test_data.values, X_test) == 0.0\n",
        "assert precision(test_data.values, Y_test) == 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how well our model is doing."
      ],
      "metadata": {
        "id": "7DVV5lqrua_O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "U-ssEJ3x7uhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e372793-b1ef-48bd-b3d2-2ead4f6d12da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 precision 62.8%\n",
            "Top-5 precision 79.1%\n"
          ]
        }
      ],
      "source": [
        "top1 = precision(test_data.values, mapping.predict(X_test), 1)\n",
        "print(f\"Top-1 precision {100 * top1:.1f}%\")\n",
        "\n",
        "top5 = precision(test_data.values, mapping.predict(X_test), 5)\n",
        "print(f\"Top-5 precision {100 * top5:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf6Ou8bx7uhH"
      },
      "source": [
        "## Making it better (orthogonal Procrustean problem) (0.3 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oLs-drN7uhK"
      },
      "source": [
        "It can be shown that a self-consistent linear mapping between semantic spaces should be orthogonal. \n",
        "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
        "\n",
        "$$(W^T)^*= \\arg\\min_{W^T} \\|XW^T - Y\\|_F \\text{, where: } W^TW = I$$\n",
        "\n",
        "$$I \\text{- identity matrix}$$\n",
        "\n",
        "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
        "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
        "$$(W^T)^*=UV^T$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DdFQ7qti7uhL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Compute the orthogonal mapping (W^T)^* as defined in formula above.\n",
        "U, _, V_T = np.linalg.svd(X_train.T @ Y_train)\n",
        "mapping = U @ V_T"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our `mapping` is just a numpy array, meaning that it has no `predict` method. However, from the formulae above we know, that prediction is done using the matrix multiplication:"
      ],
      "metadata": {
        "id": "sehLFmlBysc-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OVOFYYa37uhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c5f8f7-deec-40f8-bd68-f7bc8113e5c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('–∞–ø—Ä–µ–ª—å', 0.8245131969451904),\n",
              " ('–∏—é–Ω—å', 0.805662989616394),\n",
              " ('—Å–µ–Ω—Ç—è–±—Ä—å', 0.8055761456489563),\n",
              " ('–º–∞—Ä—Ç', 0.8032935261726379),\n",
              " ('–æ–∫—Ç—è–±—Ä—å', 0.7987102270126343),\n",
              " ('–∏—é–ª—å', 0.7946797013282776),\n",
              " ('–Ω–æ—è–±—Ä—å', 0.7939636707305908),\n",
              " ('–∞–≤–≥—É—Å—Ç', 0.7938189506530762),\n",
              " ('—Ñ–µ–≤—Ä–∞–ª—å', 0.7923861145973206),\n",
              " ('–¥–µ–∫–∞–±—Ä—å', 0.7715375423431396)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "august = uk_emb[\"—Å–µ—Ä–ø–µ–Ω—å\"] @ mapping\n",
        "ru_emb.most_similar([august])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compute our precision values and see, whether our trick did improve the results."
      ],
      "metadata": {
        "id": "h4qKCmq7zJDK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "r297sYP37uhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5c090e-6dde-46c1-8cd9-05b0835cd7aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 precision 64.4%\n",
            "Top-5 precision 79.9%\n"
          ]
        }
      ],
      "source": [
        "top1 = precision(test_data.values, X_test @ mapping, 1)\n",
        "print(f\"Top-1 precision {100 * top1:.1f}%\")\n",
        "\n",
        "top5 = precision(test_data.values, X_test @ mapping, 5)\n",
        "print(f\"Top-5 precision {100 * top5:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='darkviolet'><i> \n",
        "‚úèÔ∏è –°—Ç–∞–ª–æ –Ω–µ–º–Ω–æ–≥–æ –ª—É—á—à–µ, —á–µ–º –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –ø—É–Ω–∫—Ç–µ.\n",
        "</i></font>"
      ],
      "metadata": {
        "id": "feXkhTlYhSmH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvUZ72U5AfJg"
      },
      "source": [
        "## Unsupervised embedding-based MT (0.4 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLyuVfHBLrJn"
      },
      "source": [
        "Now, let's build our word embeddings-based translator!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPAURW1CMuP7"
      },
      "source": [
        "Firstly, download OPUS Tatoeba corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "F80kUKzQMsDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6dd0d2a-0295-4caf-848c-98170460b205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-12 11:26:23--  https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1819128 (1.7M) [application/gzip]\n",
            "Saving to: ‚Äòuk.txt.gz‚Äô\n",
            "\n",
            "uk.txt.gz           100%[===================>]   1.73M  6.88MB/s    in 0.3s    \n",
            "\n",
            "2022-04-12 11:26:24 (6.88 MB/s) - ‚Äòuk.txt.gz‚Äô saved [1819128/1819128]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz\n",
        "!gzip -d ./uk.txt.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2MV3VvoVUX5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c03d28-92ae-4690-ecd6-33d07c6c26aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['–Ø –≤–∂–µ –∑–∞–∫—ñ–Ω—á—É –∫–æ–ª–µ–¥–∂, –∫–æ–ª–∏ –≤–∏ –≤–µ—Ä–Ω–µ—Ç–µ—Å—è –∑ –ê–º–µ—Ä–∏–∫–∏.\\n',\n",
              " '–í—ñ–Ω –Ω–∞–∫–∞–∑–∞–≤ –º–µ–Ω—ñ –Ω–µ–≥–∞–π–Ω–æ –≤–∏–π—Ç–∏ –∑ –∫—ñ–º–Ω–∞—Ç–∏.\\n',\n",
              " '–Ø–∫ –±–∏ —Ç–∏ –Ω–µ –Ω–∞–º–∞–≥–∞–≤—Å—è, —Ç–∏ –Ω–µ –≤–∏–≤—á–∏—à –∞–Ω–≥–ª—ñ–π—Å—å–∫—É –∑–∞ –¥–≤–∞-—Ç—Ä–∏ –º—ñ—Å—è—Ü—ñ.\\n',\n",
              " '–ü–æ–∫–∏ —è –Ω–µ –ø–æ–¥–∑–≤–æ–Ω–∏–≤, –≤—ñ–Ω –Ω–µ –ø—Ä–∏–π—à–æ–≤.\\n',\n",
              " '–£ –≤—Å–µ—Å–≤—ñ—Ç—ñ –±–∞–≥–∞—Ç–æ –≥–∞–ª–∞–∫—Ç–∏–∫.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "with open('./uk.txt', 'r') as f:\n",
        "    uk_corpus = f.readlines()\n",
        "\n",
        "# To save your time and CPU, feel free to use first 1000 sentences of the corpus\n",
        "uk_corpus = uk_corpus[:1000]\n",
        "uk_corpus[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's translate these sentences word-by-word. Before that, however, don't forget to tokenize your sentences. For that you may (or may not) find the `nltk.tokenize.WordPunctTokenizer` to be very useful."
      ],
      "metadata": {
        "id": "oa3dAZHv1wjY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FGksC7l_NMi9"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tk = WordPunctTokenizer()\n",
        "\n",
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in Ukrainian (str)\n",
        "    :returns:\n",
        "        translation - sentence in Russian (str)\n",
        "\n",
        "    * find ukrainian embedding for each word in sentence\n",
        "    * transform ukrainian embedding vector\n",
        "    * find nearest russian word and replace\n",
        "    \"\"\"\n",
        "    translated = []\n",
        "    tokens = tk.tokenize(sentence)\n",
        "    for token in tokens:\n",
        "        if token in uk_emb:\n",
        "            map_ru_emb = uk_emb[token] @ mapping\n",
        "            translation = ru_emb.most_similar([map_ru_emb], topn=1)[0][0]\n",
        "            translated.append(translation)\n",
        "        else:\n",
        "            translated.append(\"UNK\")\n",
        "\n",
        "    return \" \".join(translated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "4hbbMy-tNxlf"
      },
      "outputs": [],
      "source": [
        "assert translate(\".\") == \".\"\n",
        "assert translate(\"1 , 3\") == \"1 , 3\"\n",
        "assert translate(\"–∫—ñ—Ç –∑–ª–æ–≤–∏–≤ –º–∏—à—É\") == \"–∫–æ—Ç –ø–æ–π–º–∞–ª –º—ã—à–∫—É\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia6I2ce7O_HI"
      },
      "source": [
        "Now you can play with your model and try to get as accurate translations as possible. **Note**: one big issue is out-of-vocabulary words. Try to think of various ways of handling it (you can start with translating each of them to a special **UNK** token and then move to more sophisticated approaches). Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ap1W7ZCeOAVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212524b0-9fba-4039-f062-3d51995df130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uk: –Ø –≤–∂–µ –∑–∞–∫—ñ–Ω—á—É –∫–æ–ª–µ–¥–∂, –∫–æ–ª–∏ –≤–∏ –≤–µ—Ä–Ω–µ—Ç–µ—Å—è –∑ –ê–º–µ—Ä–∏–∫–∏.\n",
            "ru: –Ø —É–∂–µ –∑–∞–∫–æ–Ω—á—É –∫–æ–ª–ª–µ–¥–∂ , –∫–æ–≥–¥–∞ –º—ã –ø—Ä–∏–±–µ–∂–∏—à—å —Å–æ –ê–º–µ—Ä–∏–∫–∏ .\n",
            "\n",
            "uk: –ú—ñ—Å—Ç–æ –±–æ–º–±–∞—Ä–¥—É–≤–∞–ª–∏ –≤–æ—Ä–æ–∂—ñ –ª—ñ—Ç–∞–∫–∏.\n",
            "ru: –ì–æ—Ä–æ–¥ –±–æ–º–±–∏–ª–∏ –≤—Ä–∞–∂–¥–µ–±–Ω—ã–µ —Å–∞–º–æ–ª–µ—Ç—ã .\n",
            "\n",
            "uk: –ú–æ–∂–ª–∏–≤–æ, —è –∞–Ω—Ç–∏—Å–æ—Ü—ñ–∞–ª—å–Ω–∏–π, –∞–ª–µ —Ü–µ –Ω–µ –æ–∑–Ω–∞—á–∞—î, —â–æ —è –Ω–µ —Å–ø—ñ–ª–∫—É—é—Å—è –∑ –ª—é–¥—å–º–∏.\n",
            "ru: –í–æ–∑–º–æ–∂–Ω–æ , –º–Ω–æ–π –∞–Ω—Ç–∏—Å–æ—Ü–∏–∞–ª—å–Ω—ã–π , –∫–æ–Ω–µ—á–Ω–æ —ç—Ç–æ –Ω–µ –æ–∑–Ω–∞—á–∞–µ—Ç , —á—Ç–æ –º–Ω–æ–π –Ω–µ –æ–±—â–∞—é—Å—å —Å–æ –ª—é–¥—å–º–∏ .\n",
            "\n",
            "uk: –¶—å–æ–≥–æ —Ä–∞–Ω–∫—É –≤–∏–ø–∞–ª–∞ —Ä–æ—Å–∞.\n",
            "ru: –í–ø—Ä–æ—á–µ–º —É—Ç—Ä–∞ –≤—ã–ø–∞–ª–∞ —Ä–æ—Å–∞ .\n",
            "\n",
            "uk: –ë—ñ–¥–∞ –Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –æ–¥–Ω–∞.\n",
            "ru: –ë–µ–¥–∞ –Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—Ç –æ–¥–Ω–∞ .\n",
            "\n",
            "uk: –ü–æ–¥–∏–≤–∏—Å—è –Ω–∞ —Ç–æ–π –¥–∏–º.\n",
            "ru: –ü–æ—Å–º–æ—Ç—Ä–∏ –ø–æ —Ç–æ—Ç –¥—ã–º .\n",
            "\n",
            "uk: –Ø –∑–∞–º–æ–≤–∏–≤ –¥–≤–∞ –≥–∞–º–±—É—Ä–≥–µ—Ä–∞.\n",
            "ru: –Ø –∑–∞–∫–∞–∑–∞–ª –¥–≤–∞ –≥–∞–º–±—É—Ä–≥–µ—Ä–∞ .\n",
            "\n",
            "uk: –Ø –Ω–µ —Ö–æ—Ç—ñ–≤ –Ω—ñ–∫–æ–≥–æ –æ–±—Ä–∞–∑–∏—Ç–∏.\n",
            "ru: –Ø –Ω–µ —Ö–æ—Ç–µ–ª –Ω–∏–∫–æ–≥–æ –æ–±–∏–¥–µ—Ç—å .\n",
            "\n",
            "uk: –ì–æ—Ä–∞ –≤–∫—Ä–∏—Ç–∞ —Å–Ω—ñ–≥–æ–º.\n",
            "ru: –ì–æ—Ä–∞ –ø–æ–∫—Ä—ã—Ç–∞ —Å–Ω–µ–≥–æ–º .\n",
            "\n",
            "uk: –ù–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ—ñ—ó –≤ –¥—ñ–≤—á–∏–Ω–∏ –∫–æ—Ä–æ–Ω–∞ –Ω–µ –∑ –∑–æ–ª–æ—Ç–∞, –∞ –∑ –∫–≤—ñ—Ç—ñ–≤.\n",
            "ru: –ø–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –≤–æ –¥–µ–≤—É—à–∫–∏ –∫–æ—Ä–æ–Ω–∞ –Ω–µ —Å–æ –∑–æ–ª–æ—Ç–∞ , –∞ —Å–æ —Ü–≤–µ—Ç–æ–≤ .\n",
            "\n",
            "uk: –£ –º–µ–Ω–µ —î –º—Ä—ñ—è.\n",
            "ru: –í–æ –º–µ–Ω—è –¢–æ –º–µ—á—Ç–∞ .\n",
            "\n",
            "uk: –Ø –ø—Ä–∏—ó—Ö–∞–≤ —É –Ø–ø–æ–Ω—ñ—é –∑ –ö–∏—Ç–∞—é.\n",
            "ru: –Ø –ø—Ä–∏–µ—Ö–∞–ª –≤–æ –Ø–ø–æ–Ω–∏—é —Å–æ –ö–∏—Ç–∞—è .\n",
            "\n",
            "uk: –ù–∞ –ø—ñ–≤–Ω–æ—á—ñ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –®–æ—Ç–ª–∞–Ω–¥—ñ—è; –Ω–∞ –ø—ñ–≤–¥–Ω—ñ ‚Äî –ê–Ω–≥–ª—ñ—è; –Ω–∞ –∑–∞—Ö–æ–¥—ñ ‚Äî –£–µ–ª—å—Å; —ñ —â–µ –¥–∞–ª—ñ –Ω–∞ –∑–∞—Ö–æ–¥—ñ ‚Äî –ü—ñ–≤–Ω—ñ—á–Ω–∞ –Ü—Ä–ª–∞–Ω–¥—ñ—è.\n",
            "ru: –ø–æ —Å–µ–≤–µ—Ä –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –®–æ—Ç–ª–∞–Ω–¥–∏—è ; –ø–æ —é–≥–µ ‚Äî –ê–Ω–≥–ª–∏—è ; –ø–æ –≤–æ—Å—Ç–æ–∫–µ ‚Äî –£—ç–ª—å—Å ; –∏ –µ—âe –¥–∞–ª—å—à–µ –ø–æ –≤–æ—Å—Ç–æ–∫–µ ‚Äî —Å–µ–≤–µ—Ä–Ω–∞—è –ò—Ä–ª–∞–Ω–¥–∏—è .\n",
            "\n",
            "uk: –ô–æ–≥–æ —Ä—ñ–¥–Ω–∞ –∫—Ä–∞—ó–Ω–∞ ‚Äî –ù—ñ–º–µ—á—á–∏–Ω–∞.\n",
            "ru: –ï–≥–æ —Ä–æ–¥–Ω–∞—è —Å—Ç—Ä–∞–Ω–∞ ‚Äî –ì–µ—Ä–º–∞–Ω–∏—è .\n",
            "\n",
            "uk: –ë–µ—Ä–Ω ‚Äî —Å—Ç–æ–ª–∏—Ü—è –®–≤–µ–π—Ü–∞—Ä—ñ—ó.\n",
            "ru: –ë–µ—Ä–Ω ‚Äî —Å—Ç–æ–ª–∏—Ü–∞ –®–≤–µ–π—Ü–∞—Ä–∏–∏ .\n",
            "\n",
            "uk: –í—ñ–Ω —á–µ–∫–∞–≤ –Ω–∞ –Ω—å–æ–≥–æ –¥–æ –¥–µ—Å—è—Ç–æ—ó –≥–æ–¥–∏–Ω–∏.\n",
            "ru: –û–Ω –∂–¥–∞–ª –ø–æ –Ω–µ–≥–æ –∫ –¥–µ—Å—è—Ç–æ–π —á–∞—Å–∞ .\n",
            "\n",
            "uk: –¢–∏ –º–æ–∂–µ—à –≤–∑—è—Ç–∏ —Ü—é –∫–Ω–∏–≥—É –¥–∞—Ä–æ–º.\n",
            "ru: –¢—ã –º–æ–∂–µ—à—å –≤–∑—è—Ç—å —Ç—É –∫–Ω–∏–≥—É –¥–∞—Ä–æ–º .\n",
            "\n",
            "uk: –¶–µ–π —Ä–æ–º–∞–Ω –Ω–∞–ø–∏—Å–∞–≤ –≤—ñ–¥–æ–º–∏–π –∞–º–µ—Ä–∏–∫–∞–Ω—Å—å–∫–∏–π –ø–∏—Å—å–º–µ–Ω–Ω–∏–∫.\n",
            "ru: –¢–∞–∫–æ–π —Ä–æ–º–∞–Ω —Å–æ—á–∏–Ω–∏–ª –∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å .\n",
            "\n",
            "uk: –ó–∞–±—Ä–æ–Ω—é–π—Ç–µ, –±—É–¥—å—Ç–µ –ª–∞—Å–∫–∞–≤—ñ, –∫—ñ–º–Ω–∞—Ç—É –±—ñ–ª—è –º—ñ–∂–Ω–∞—Ä–æ–¥–Ω–æ–≥–æ –∞–µ—Ä–æ–ø–æ—Ä—Ç—É –≤ –¢–æ—Ä–æ–Ω—Ç–æ.\n",
            "ru: –∑–∞–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å , –±—É–¥—Ç–µ –ª–∞—Å–∫–æ–≤—ã–µ , –∫–æ–º–Ω–∞—Ç—É –≤–æ–∑–ª–µ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–≥–æ –∞—ç—Ä–æ–ø–æ—Ä—Ç–∞ –≤–æ –¢–æ—Ä–æ–Ω—Ç–æ .\n",
            "\n",
            "uk: –í—ñ–Ω –∑–Ω–∞—î, —â–æ —Ç–∏ –π–æ–≥–æ –∫–æ—Ö–∞—î—à?\n",
            "ru: –û–Ω –∑–Ω–∞–µ—Ç , —á—Ç–æ —Ç—ã –µ–≥–æ –≤–ª—é–±–∏—Ç—Å—è ?\n",
            "\n",
            "uk: –Ø –∑–Ω–∞—é, —â–æ —Ç–∏ –±–∞–≥–∞—Ç–∏–π.\n",
            "ru: –Ø –∑–Ω–∞—é , —á—Ç–æ —Ç—ã –±–æ–≥–∞—Ç—ã–π .\n",
            "\n",
            "uk: –¢—ñ, —Ö—Ç–æ –≤—Å–µ –∑–∞–±—É–≤–∞—é—Ç—å, —â–∞—Å–ª–∏–≤—ñ.\n",
            "ru: –¢–µ , –∫—Ç–æ –≤—Å—ë –∑–∞–±—ã–≤–∞—é—Ç , —Å—á–∞—Å—Ç–ª–∏–≤—ã–µ .\n",
            "\n",
            "uk: –í —Ü—ñ–π —Ä—ñ—á—Ü—ñ –Ω–µ–±–µ–∑–ø–µ—á–Ω–æ –ø–ª–∞–≤–∞—Ç–∏.\n",
            "ru: –í–æ —ç—Ç–æ–π —Ä–µ–∫–µ –æ–ø–∞—Å–Ω–æ –ø–ª–∞–≤–∞—Ç—å .\n",
            "\n",
            "uk: –ü—Ä–∏–π—à–æ–≤, –ø–æ–±–∞—á–∏–≤, –ø–µ—Ä–µ–º—ñ–≥.\n",
            "ru: –ø—Ä–∏—à–µ–ª , —É–≤–∏–¥–µ–ª , –ø–æ–±–µ–¥–∏–ª .\n",
            "\n",
            "uk: –Ø —Ö–æ–¥–∂—É –¥–æ —à–∫–æ–ª–∏ –ø—ñ—à–∫–∏.\n",
            "ru: –Ø —Ö–æ–∂—É –∫ —à–∫–æ–ª—ã –ø–µ—à–∫–æ–º .\n",
            "\n",
            "uk: –ù–µ —Ç–≤–æ—è —Å–ø—Ä–∞–≤–∞!\n",
            "ru: –ù–µ –º–æ—è –¥–µ–ª–æ !\n",
            "\n",
            "uk: –ù–µ –∑–∞–±—É–¥—å –∫–≤–∏—Ç–æ–∫.\n",
            "ru: –ù–µ –∑–∞–±—É–¥—å –±–∏–ª–µ—Ç .\n",
            "\n",
            "uk: –•—Ç–æ –≤—ñ–Ω?\n",
            "ru: –ö—Ç–æ –æ–Ω ?\n",
            "\n",
            "uk: –í–∏ –±—É–¥–µ—Ç–µ —á–∞–π —á–∏ –∫–∞–≤—É?\n",
            "ru: –í—ã –±—É–¥–µ—Ç–µ —á–∞–π –ª–∏ –∫–æ—Ñ–µ ?\n",
            "\n",
            "uk: –í—ñ–Ω –Ω–µ –ø—ñ–¥–µ –Ω–∞ –ø—ñ–∫–Ω—ñ–∫, —è–∫ —ñ —è.\n",
            "ru: –û–Ω –Ω–µ –ø–æ–π–¥–µ—Ç –ø–æ –ø–∏–∫–Ω–∏–∫ , –∫–∞–∫ –∏ –º–Ω–æ–π .\n",
            "\n",
            "uk: –ö–æ–ª–∏ –í–∏ –Ω–∞—Ä–æ–¥–∏–ª–∏—Å—è?\n",
            "ru: –ö–æ–≥–¥–∞ –í—ã —Ä–æ–¥–∏–ª–∏—Å—å ?\n",
            "\n",
            "uk: –¶–µ –º–æ—è —É–ª—é–±–ª–µ–Ω–∞ –ø—ñ—Å–Ω—è.\n",
            "ru: –≠—Ç–æ –º–æ—è –ª—é–±–∏–º–∞—è –ø–µ—Å–Ω—è .\n",
            "\n",
            "uk: –ú–∏ –º–∞–π–∂–µ —Å—ñ–º‚Äô—è.\n",
            "ru: –º—ã –ø–æ—á—Ç–∏ —Å–µ–º—å —Å–æ –º–Ω–æ–π .\n",
            "\n",
            "uk: –Ø–∫–∏–π –≥–∞—Ä–Ω–∏–π —Å—å–æ–≥–æ–¥–Ω—ñ –º—ñ—Å—è—Ü—å!\n",
            "ru: –ö–∞–∫–æ–π –∫—Ä–∞—Å–∏–≤—ã–π —Å–µ–≥–æ–¥–Ω—è –º–µ—Å—è—Ü !\n",
            "\n",
            "uk: –Ø –ø—Ä–æ—Ç–∏ –±—É–¥—å-—è–∫–∏—Ö –≤—ñ–π–Ω.\n",
            "ru: –Ø –ø—Ä–æ—Ç–∏–≤ –ª—é–±–æ–π ‚Äì –∫–æ—Ç–æ—Ä—ã—Ö –≤–æ–π–Ω—ã .\n",
            "\n",
            "uk: –ü–æ–≤–µ—Ä—Ö–Ω—è –ø–æ–≤—ñ—Ç—Ä—è–Ω–æ—ó –∫—É–ª—ñ ‚Äî –Ω–µ–µ–≤–∫–ª—ñ–¥–æ–≤–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä, —Ç–æ–º—É –¥–ª—è –Ω–µ—ó –Ω–µ –≤–∏–∫–æ–Ω—É—é—Ç—å—Å—è –ø—Ä–∞–≤–∏–ª–∞ –µ–≤–∫–ª—ñ–¥–æ–≤–æ—ó –≥–µ–æ–º–µ—Ç—Ä—ñ—ó.\n",
            "ru: –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å –≤–æ–∑–¥—É—à–Ω–æ–π —à–∞—Ä—ã ‚Äî UNK –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ , –ø–æ—Ç–æ–º—É –¥–ª—è –Ω–µ—ë –Ω–µ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –ø—Ä–∞–≤–∏–ª–∞ —Å–∏–º–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–π –≥–µ–æ–º–µ—Ç—Ä–∏–∏ .\n",
            "\n",
            "uk: –ö–∞–∂—É—Ç—å, —â–æ –∞–º–µ—Ä–∏–∫–∞–Ω—Ü—ñ –≤–≤–∞–∂–∞—é—Ç—å –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≥—Ä–æ—à–µ–π, —è–∫—É –∑–∞—Ä–æ–±–ª—è—î –ª—é–¥–∏–Ω–∞, –º—ñ—Ä–∏–ª–æ–º –π–æ–≥–æ —É–º—ñ–Ω–Ω—è.\n",
            "ru: –ì–æ–≤–æ—Ä—è—Ç , —á—Ç–æ –∞–º–µ—Ä–∏–∫–∞–Ω—Ü—ã —Å—á–∏—Ç–∞—é—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ–Ω–µ–≥ , –∫–∞–∫—É—é –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∂–µ–Ω—â–∏–Ω–∞ , –º–µ—Ä–∏–ª–æ–º –µ–≥–æ —É–º–µ–Ω–∏–µ .\n",
            "\n",
            "uk: –ú–æ–∂–Ω–∞ —è –ø—Ä–∏–º—ñ—Ä—é —Ü–µ –ø–ª–∞—Ç—Ç—è?\n",
            "ru: –ú–æ–∂–Ω–æ –º–Ω–æ–π UNK —ç—Ç–æ –ø–ª–∞—Ç—å–µ ?\n",
            "\n",
            "uk: –Ø–∫—â–æ –±—É–¥–µ –≥–∞—Ä–Ω–∞ –ø–æ–≥–æ–¥–∞, –º–∏ –¥–æ–±–µ—Ä–µ–º–æ—Å—è —Ç—É–¥–∏ –∑–∞–≤—Ç—Ä–∞.\n",
            "ru: –ï—Å–ª–∏ –±—É–¥–µ—Ç –∫—Ä–∞—Å–∏–≤–∞—è –ø–æ–≥–æ–¥–∞ , –º—ã –¥–æ–±–µ—Ä—ë–º—Å—è —Ç—É–¥–∞ –∑–∞–≤—Ç—Ä–∞ .\n",
            "\n",
            "uk: –¶–µ –±—É–≤ –∑–ª–∏–π –∑–∞—î—Ü—å.\n",
            "ru: –≠—Ç–æ –±—ã–ª –∑–ª–æ–π –∑–∞—è—Ü .\n",
            "\n",
            "uk: –û–¥–∏–Ω, –¥–≤–∞, —Ç—Ä–∏, —á–æ—Ç–∏—Ä–∏, –ø'—è—Ç—å, —à—ñ—Å—Ç—å, —Å—ñ–º, –≤—ñ—Å—ñ–º, –¥–µ–≤'—è—Ç—å, –¥–µ—Å—è—Ç—å.\n",
            "ru: –û–¥–∏–Ω , –¥–≤–∞ , —Ç—Ä–∏ , —á–µ—Ç—ã—Ä–µ , –∞—à —Å–æ –ø—è—Ç—å , –≤–æ—Å–µ–º—å , —Å–µ–º—å , –≤–æ—Å–µ–º—å , –¥–µ–≤—è—Ç—å —Å–æ –ø—è—Ç—å , –¥–µ—Å—è—Ç—å .\n",
            "\n",
            "uk: –•—Ç–æ –≤ –ª—é–±–æ–≤—ñ –Ω–µ –∑–Ω–∞—î—Ç—å—Å—è, —Ç–æ–π –≥–æ—Ä—è –Ω–µ –∑–Ω–∞—î.\n",
            "ru: –ö—Ç–æ –≤–æ –ª—é–±–≤–∏ –Ω–µ –∑–Ω–∞–µ—Ç , —Ç–æ—Ç –≥–æ—Ä—è –Ω–µ –∑–Ω–∞–µ—Ç .\n",
            "\n",
            "uk: –ô–æ–≥–æ –º–∞—Ç–∏ —Ö–≤–∏–ª—é—î—Ç—å—Å—è –∑–∞ –Ω—å–æ–≥–æ.\n",
            "ru: –ï–≥–æ –∏–º–µ—Ç—å –≤–æ–ª–Ω—É–µ—Ç—Å—è –∑–∞ –Ω–µ–≥–æ .\n",
            "\n",
            "uk: –Ø –ø–æ–≤–∞–∂–∞—é —Ç–∏—Ö, —Ö—Ç–æ —Å—Ç–∞—Ä–∞—î—Ç—å—Å—è –∑ —É—Å—ñ—Ö —Å–∏–ª.\n",
            "ru: –Ø —É–≤–∞–∂–∞—é —Ç–µ—Ö , –∫—Ç–æ —Å—Ç–∞—Ä–∞–µ—Ç—Å—è —Å–æ –≤—Å–µ—Ö —Å–∏–ª .\n",
            "\n",
            "uk: –á—Ö–Ω—è –¥—Ä—É–∂–±–∞ –ø–µ—Ä–µ—Ä–æ—Å–ª–∞ —É –≥–ª–∏–±–æ–∫–µ –∫–æ—Ö–∞–Ω–Ω—è.\n",
            "ru: –Ω–µ–æ–±—ã—á–∞–π–Ω–∞—è –¥—Ä—É–∂–±–∞ –ø–µ—Ä–µ—Ä–æ—Å–ª–∞ –≤–æ –≥–ª—É–±–æ–∫–æ–µ –ª—é–±–æ–≤—å .\n",
            "\n",
            "uk: –ö–µ–π—Ç –ø‚Äô—î –±–∞–≥–∞—Ç–æ –º–æ–ª–æ–∫–∞ –∫–æ–∂–µ–Ω –¥–µ–Ω—å.\n",
            "ru: –†–µ–π—á–µ–ª –∞—à —Å–æ –¢–æ –º–Ω–æ–≥–æ –º–æ–ª–æ–∫–∞ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å .\n",
            "\n",
            "uk: –í—ñ–Ω –∑–ª–æ–¥—ñ–π.\n",
            "ru: –û–Ω –≤–æ—Ä .\n",
            "\n",
            "uk: –®—É–º–æ–≤–æ–≥–æ –∑–∞–±—Ä—É–¥–Ω–µ–Ω–Ω—è –º–æ–∂–Ω–∞ –±—É–ª–æ –± –ø–æ–∑–±—ñ–≥–Ω—É—Ç–∏ —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –± –ª—é–¥–∏ –±—É–ª–∏ –±—ñ–ª—å—à —á—É—Ç–ª–∏–≤–∏–º–∏ –¥–æ –Ω–∞–≤–∫–æ–ª–∏—à–Ω—å–æ–≥–æ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞.\n",
            "ru: UNK –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã UNK —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã –ª—é–¥–∏ –±—ã–ª–∏ –±–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã –∫ –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥—ã .\n",
            "\n",
            "uk: –ß–∞–π –∑ –ª–∏–º–æ–Ω–æ–º, –±—É–¥—å—Ç–µ –ª–∞—Å–∫–∞–≤—ñ.\n",
            "ru: —á–∞–π —Å–æ –ª–∏–º–æ–Ω–æ–º , –±—É–¥—Ç–µ –ª–∞—Å–∫–æ–≤—ã–µ .\n",
            "\n",
            "uk: –ù–µ –ø–ª—É—Ç–∞–π –±–∞–∂–∞–Ω–Ω—è –∑ –∫–æ—Ö–∞–Ω–Ω—è–º.\n",
            "ru: –ù–µ –ø—É—Ç–∞—Ç—å –∂–µ–ª–∞–Ω–∏–µ —Å–æ –≤–ª—é–±–ª–µ–Ω–Ω–æ—Å—Ç—å—é .\n",
            "\n",
            "uk: –Ø –±–∏ –∑ –∑–∞–¥–æ–≤–æ–ª–µ–Ω–Ω—è–º –Ω–∞–ø–∏—Å–∞–≤ —Å–æ—Ç–Ω—ñ —Ä–µ—á–µ–Ω—å –≤ Tatoeb‚Äô—ñ, –∞–ª–µ –≤ –º–µ–Ω–µ —î —Å–ø—Ä–∞–≤–∏.\n",
            "ru: –Ø –±—ã —Å–æ —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ–º —Å–æ—á–∏–Ω–∏–ª —Å–æ—Ç–Ω–∏ —Å–ª–æ–∂–Ω–æ–ø–æ–¥—á–∏–Ω—ë–Ω–Ω—ã–µ –≤–æ UNK —Å–æ –∏ , –∫–æ–Ω–µ—á–Ω–æ –≤–æ –º–µ–Ω—è –¢–æ –¥–µ–ª–∞ .\n",
            "\n",
            "uk: –î–∞–π—Ç–µ –º–µ–Ω—ñ —Ñ—ñ–ª—ñ–∂–∞–Ω–∫—É –∫–∞–≤–∏.\n",
            "ru: –î–∞–π—Ç–µ –º–Ω–µ —á–∞—à–µ—á–∫—É –∫–æ—Ñ–µ .\n",
            "\n",
            "uk: –ê–ª–µ –∂ —Ç–∏ –Ω—ñ–∫–æ–ª–∏ –º–µ–Ω—ñ –ø—Ä–æ —Ü–µ –Ω–µ —Ä–æ–∑–ø–æ–≤—ñ–¥–∞–ª–∞!\n",
            "ru: –≤–µ–¥—å –∂–µ —Ç—ã –Ω–∏–∫–æ–≥–¥–∞ –º–Ω–µ –æ —ç—Ç–æ –Ω–µ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ !\n",
            "\n",
            "uk: –£ —Ç–µ–±–µ –±—É–¥—É—Ç—å –ø—Ä–æ–±–ª–µ–º–∏, —è–∫—â–æ —Ç–≤–æ—ó –±–∞—Ç—å–∫–∏ –¥–æ–≤—ñ–¥–∞—é—Ç—å—Å—è.\n",
            "ru: –í–æ —Ç–µ–±—è –±—É–¥—É—Ç –ø—Ä–æ–±–ª–µ–º—ã , –µ—Å–ª–∏ —Ç–≤–æ–∏ —Ä–æ–¥–∏—Ç–µ–ª–∏ —É–∑–Ω–∞—é—Ç .\n",
            "\n",
            "uk: –ó–∞–ø–∞—Ö —Ç—Ä–æ—è–Ω–¥ –Ω–∞–ø–æ–≤–Ω–∏–≤ –∫—ñ–º–Ω–∞—Ç—É.\n",
            "ru: –ó–∞–ø–∞—Ö —Ä–æ–∑ –Ω–∞–ø–æ–ª–Ω–∏–ª –∫–æ–º–Ω–∞—Ç—É .\n",
            "\n",
            "uk: –Ø–∫ —É —Ç–µ–±–µ —Å–ø—Ä–∞–≤–∏?\n",
            "ru: –ö–∞–∫ –≤–æ —Ç–µ–±—è –¥–µ–ª–∞ ?\n",
            "\n",
            "uk: –¶–µ –º–æ—ó —à—Ç–∞–Ω–∏.\n",
            "ru: –≠—Ç–æ –º–æ–∏ —à—Ç–∞–Ω—ã .\n",
            "\n",
            "uk: –ù—ñ, –¥—è–∫—É—é.\n",
            "ru: –ù–ï—Ç , —Å–ø–∞—Å–∏–±–æ .\n",
            "\n",
            "uk: –Ø –Ω–µ —Ä–æ–∑—É–º—ñ—é, —á–æ–º—É –ù—ñ–º–µ—á—á–∏–Ω–∞ –ø–µ—Ä–µ–º–æ–≥–ª–∞ –Ω–∞ –Ñ–≤—Ä–æ–±–∞—á–µ–Ω–Ω—ñ.\n",
            "ru: –Ø –Ω–µ –ø–æ–Ω–∏–º–∞—é , –ø–æ—á–µ–º—É –ì–µ—Ä–º–∞–Ω–∏—è –ø–æ–±–µ–¥–∏–ª–∞ –ø–æ –ï–≤—Ä–æ–≤–∏–¥–µ–Ω–∏–∏ .\n",
            "\n",
            "uk: –î–æ–±—Ä–∏–π –≤–µ—á—ñ—Ä.\n",
            "ru: –î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä .\n",
            "\n",
            "uk: –ó —é–±—ñ–ª–µ—î–º –û–ª–µ–∫—Å—ñ—è –î—É–¥–∞—Ä–µ–≤–∞ –ø—Ä–∏–≤—ñ—Ç–∞–≤ –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç –ë—ñ–ª–æ—Ä—É—Å—ñ –û–ª–µ–∫—Å–∞–Ω–¥—Ä –õ—É–∫–∞—à–µ–Ω–∫–æ.\n",
            "ru: –°–æ UNK –ê–ª–µ–∫—Å–µ—è –ü–∞–ª–∞—à–∫–∞ –ø–æ–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –ë–µ–ª–æ—Ä—É—Å—Å–∏–∏ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –õ—É–∫–∞—à–µ–Ω–∫–æ .\n",
            "\n",
            "uk: –ß—É–º–∞—Ü—å–∫–∏–π —à–ª—è—Ö ‚Äî —à–∏—Ä–æ–∫–∏–π –ø–æ—è—Å —ñ–∑ –¥–∞–ª–µ–∫–∏—Ö –∑—ñ—Ä–æ–∫, –∫–æ–∂–Ω–∞ –∑—ñ—Ä–∫–∞ ‚Äî —Å–æ–Ω—Ü–µ, —Ç–∞–∫–µ —è–∫ –Ω–∞—à–µ.\n",
            "ru: –ú–ª–µ—á–Ω—ã–π –ø—É—Ç—å ‚Äî —à–∏—Ä–æ–∫–∏–π –ø–æ—è—Å —Å–æ –¥–∞–ª–µ–∫–∏—Ö –∑–≤—ë–∑–¥ , –∫–∞–∂–¥–∞—è –∑–≤–µ–∑–¥–∞ ‚Äî —Å–æ–ª–Ω—Ü–µ , —Ç–∞–∫–æ–µ –∫–∞–∫ –Ω–∞—à–µ .\n",
            "\n",
            "uk: –ù–µ–∑–≤–∏—á–∞–π–Ω–æ –±–∞—á–∏—Ç–∏ —Ä–æ–∫-–∑—ñ—Ä–æ–∫ –∑ –∫—Ä–∞–≤–∞—Ç–∫–æ—é!\n",
            "ru: —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω–æ –≤–∏–¥–µ—Ç—å —Ä–æ–∫ ‚Äì –∑–≤—ë–∑–¥ —Å–æ –≥–∞–ª—Å—Ç—É–∫ !\n",
            "\n",
            "uk: –£—Å–µ –ø–µ—á–∏–≤–æ —É —Ñ–æ—Ä–º—ñ –∑—ñ—Ä–æ–∫.\n",
            "ru: –≤—Å—ë –ø–µ—á–µ–Ω—å–µ –≤–æ —Ñ–æ—Ä–º–µ –∑–≤—ë–∑–¥ .\n",
            "\n",
            "uk: –©–æ –º–µ–Ω—ñ –≤–¥—è–≥–Ω—É—Ç–∏ ‚Äî —à—Ç–∞–Ω–∏ —á–∏ —Å–ø—ñ–¥–Ω–∏—Ü—é?\n",
            "ru: –ß–¢–æ –º–Ω–µ –æ–¥–µ—Ç—å ‚Äî —à—Ç–∞–Ω—ã –ª–∏ —é–±–∫—É ?\n",
            "\n",
            "uk: –ì–∞—Ä—Ç–º–∞–Ω –í—ñ—Ç–≤–µ—Ä ‚Äî –≤—ñ–¥–æ–º–∏–π –ª—å–≤—ñ–≤—Å—å–∫–∏–π —Å–∫—É–ª—å–ø—Ç–æ—Ä.\n",
            "ru: –ö—Ä–∞—É—Å—Å —É—Ç–≤–µ—Ä–∂–¥–∞–ª ‚Äî –∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–æ—Å–∫–æ–≤—Å–∫–∏–π —Å–∫—É–ª—å–ø—Ç–æ—Ä .\n",
            "\n",
            "uk: –¢–æ –±—É–≤ –∑–ª–∏–π –∫—Ä–æ–ª–∏–∫.\n",
            "ru: –û–π –±—ã–ª –∑–ª–æ–π –∫—Ä–æ–ª–∏–∫ .\n",
            "\n",
            "uk: –ú–æ–∂–µ—à –≤–∑—è—Ç–∏ –±—É–¥—å-—è–∫–∏–π, —â–æ —Ç–æ–±—ñ –¥–æ —Å–ø–æ–¥–æ–±–∏.\n",
            "ru: –ú–æ–∂–µ—à—å –≤–∑—è—Ç—å –ª—é–±–æ–π ‚Äì –∫–æ—Ç–æ—Ä—ã–π , —á—Ç–æ —Ç–µ–±–µ –∫ –æ—Ç–≤—Ä–∞—Ç–∏—Ç—å—Å—è .\n",
            "\n",
            "uk: –ó–≤–∏—á–∞–π–Ω–æ —è –ø—ñ–¥—É.\n",
            "ru: –ö–æ–Ω–µ—á–Ω–æ –º–Ω–æ–π –ø–æ–π–¥—É .\n",
            "\n",
            "uk: –®–æ–≤–∫–æ–ø—Ä—è–¥–∏ –ø—Ä—è–¥—É—Ç—å –∫–æ–∫–æ–Ω–∏.\n",
            "ru: —à–µ–ª–∫–æ–≤–∏—á–Ω—ã–µ –ø—Ä—è–¥—É—Ç –∫–æ–∫–æ–Ω—ã .\n",
            "\n",
            "uk: –©–æ –± —Ç–∏ –∑—Ä–æ–±–∏–ª–∞, —è–∫—â–æ –± —É —Ç–µ–±–µ –±—É–ª–æ, —Å–∫–∞–∂—ñ–º, –¥–µ—Å—è—Ç—å —Ç–∏—Å—è—á –¥–æ–ª–∞—Ä—ñ–≤?\n",
            "ru: –ß–¢–æ –±—ã —Ç—ã —Å–¥–µ–ª–∞–ª–∞ , –µ—Å–ª–∏ –±—ã –≤–æ —Ç–µ–±—è –±—ã–ª–æ , –∑–∞–º–µ—á—É , –¥–µ—Å—è—Ç—å —Ç—ã—Å—è—á –¥–æ–ª–ª–∞—Ä–æ–≤ ?\n",
            "\n",
            "uk: –í—ñ–Ω –¥—É–º–∞—î, —â–æ –≤—ñ–Ω —Ö—Ç–æ—Å—å, –∞ –Ω–∞—Å–ø—Ä–∞–≤–¥—ñ –≤—ñ–Ω –Ω—ñ—Ö—Ç–æ.\n",
            "ru: –û–Ω –¥—É–º–∞–µ—Ç , —á—Ç–æ –æ–Ω –∫—Ç–æ-—Ç–æ , –∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –æ–Ω –Ω–∏–∫—Ç–æ .\n",
            "\n",
            "uk: –í–æ–Ω–∞ –¥—É–∂–µ –ø–∏—à–∞—î—Ç—å—Å—è —Å–≤–æ—î—é –∫–æ–ª–µ–∫—Ü—ñ—î—é –º–∞—Ä–æ–∫.\n",
            "ru: –æ–Ω–∞ –æ—á–µ–Ω—å –≥–æ—Ä–¥–∏—Ç—Å—è —Å–≤–æ–µ—é –∫–æ–ª–ª–µ–∫—Ü–∏–µ–π –º–∞—Ä–æ–∫ .\n",
            "\n",
            "uk: –í—ñ–Ω –¥—É–∂–µ –ø—Ä–æ—Å—Ç–∏–π...\n",
            "ru: –û–Ω –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ–π ...\n",
            "\n",
            "uk: –Ø–∫–∞ —Ç–∏ –¥–æ–±—Ä–∞!\n",
            "ru: –ö–∞–∫–∞—è —Ç—ã –¥–æ–±—Ä–∞ !\n",
            "\n",
            "uk: –Ø–∫ —è –∑–∞ —Ç–æ–±–æ—é —Å–∫—É—á–∏–≤!\n",
            "ru: –ö–∞–∫ –º–Ω–æ–π –∑–∞ —Ç–æ–±–æ–π —Å–æ—Å–∫—É—á–∏–ª—Å—è !\n",
            "\n",
            "uk: –¶–µ –≤—Å–µ, —â–æ —è –∑–Ω–∞—é.\n",
            "ru: –≠—Ç–æ –≤—Å—ë , —á—Ç–æ –º–Ω–æ–π –∑–Ω–∞—é .\n",
            "\n",
            "uk: –¢–∏ –≤–µ–¥–µ—à —â–æ–¥–µ–Ω–Ω–∏–∫?\n",
            "ru: –¢—ã –≤–µ–¥—ë—à—å –¥–Ω–µ–≤–Ω–∏–∫ ?\n",
            "\n",
            "uk: –¢–æ–±—ñ –≤–∏—Ä—ñ—à—É–≤–∞—Ç–∏.\n",
            "ru: –¢–µ–±–µ —Ä–µ—à–∞—Ç—å .\n",
            "\n",
            "uk: –¶–µ –ø–æ—à—Ç–∞, –∞ —Ç–æ ‚Äî –±–∞–Ω–∫.\n",
            "ru: –≠—Ç–æ –ø–æ—á—Ç–∞ , –∞ —Ç–æ ‚Äî –±–∞–Ω–∫ .\n",
            "\n",
            "uk: –¶–µ –≤—Å–µ, —â–æ —è —Ö–æ—á—É –∑—Ä–æ–±–∏—Ç–∏.\n",
            "ru: –≠—Ç–æ –≤—Å—ë , —á—Ç–æ –º–Ω–æ–π —Ö–æ—á—É —Å–¥–µ–ª–∞—Ç—å .\n",
            "\n",
            "uk: –Ø –≤–ø–µ—Ä—à–µ –¥–∏–≤–ª—é—Å—è —Ç–∞–∫–∏–π —Å—Ç—Ä–∞—à–Ω–∏–π —Ñ—ñ–ª—å–º.\n",
            "ru: –Ø –≤–ø–µ—Ä–≤—ã–µ —Å–º–æ—Ç—Ä—é —Ç–∞–∫–æ–π —Å—Ç—Ä–∞—à–Ω—ã–π —Ñ–∏–ª—å–º .\n",
            "\n",
            "uk: –¶—è –ø—ñ—Å–Ω—è –Ω–∞–≥–∞–¥—É—î –º–µ–Ω—ñ –ø—Ä–æ –¥—ñ–º.\n",
            "ru: –≠—Ça –ø–µ—Å–Ω—è –Ω–∞–ø–æ–º–∏–Ω–∞–µ—Ç –º–Ω–µ –æ –¥–æ–º .\n",
            "\n",
            "uk: –•—ñ—Ä–æ—Å—ñ —Ç—É—Ç?\n",
            "ru: –•–∏—Ä–æ—Å–∏ –∑–¥–µ—Å—å ?\n",
            "\n",
            "uk: –ú–µ–Ω–µ –∑–≤—É—Ç—å –î–∂–µ–∫.\n",
            "ru: –ú–µ–Ω—è –∑–æ–≤—É—Ç –≠–¥–¥–∏ .\n",
            "\n",
            "uk: –Ø–∫ –ª—é–¥–∏–Ω–∞ –∂–∏–≤–µ, —Ç–∞–∫ –≤–æ–Ω–∞ —ñ –ø–æ–º—Ä–µ.\n",
            "ru: –ö–∞–∫ –∂–µ–Ω—â–∏–Ω–∞ –∂–∏–≤–µ—Ç , —Ç–∞–∫ –æ–Ω–∞ –∏ —É–º—Ä–µ—Ç .\n",
            "\n",
            "uk: –Ø —Ç—É—Ç —É–∂–µ –¥–≤—ñ –≥–æ–¥–∏–Ω–∏.\n",
            "ru: –Ø –∑–¥–µ—Å—å —É–∂–µ –¥–≤–µ —á–∞—Å–∞ .\n",
            "\n",
            "uk: –ú–µ–Ω—ñ —Ç—Ä–µ–±–∞ –≤–∏–±–∞—á–∏—Ç–∏—Å—å –ø–µ—Ä–µ–¥ –ï–Ω.\n",
            "ru: –ú–Ω–µ –Ω–∞–¥–æ –∏–∑–≤–∏–Ω–∏—Ç—å—Å—è –ø–µ—Ä–µ–¥ –ù–± .\n",
            "\n",
            "uk: –°—å–æ–≥–æ–¥–Ω—ñ —è –±–∞—á–∏–≤ —à–ø–∞–∫–∞.\n",
            "ru: –°–µ–≥–æ–¥–Ω—è –º–Ω–æ–π –≤–∏–¥–µ–ª —Å–∫–≤–æ—Ä—Ü–∞ .\n",
            "\n",
            "uk: ¬´–°–∫—ñ–ª—å–∫–∏ –∫–æ—à—Ç—É—î —Ü—è –Ω–æ—Å–æ–≤–∞ —Ö—É—Å—Ç–æ—á–∫–∞?¬ª ‚Äî ¬´–î–µ–≤'—è–Ω–æ—Å—Ç–æ –ø'—è—Ç—å —Ü–µ–Ω—Ç—ñ–≤¬ª.\n",
            "ru: ¬´ –°–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç—å —Ç–∞ –Ω–æ—Å–æ–≤–∞—è –∫–æ—Å—ã–Ω–æ—á–∫–∞ UNK ‚Äî ¬´ —Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å —Å–æ –¥–≤–∞–¥—Ü–∞—Ç—å –∞—à —Å–æ –ø—è—Ç—å —Ü–µ–Ω—Ç–æ–≤ UNK\n",
            "\n",
            "uk: –†–∞–Ω–µ–Ω—ñ –≤–µ–¥–º–µ–¥—ñ, —è–∫ –ø—Ä–∞–≤–∏–ª–æ, –¥—É–∂–µ –Ω–µ–±–µ–∑–ø–µ—á–Ω—ñ.\n",
            "ru: —Å–æ–ª–¥–∞—Ç—ã –º–µ–¥–≤–µ–¥–∏ , –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ , –æ—á–µ–Ω—å –æ–ø–∞—Å–Ω—ã–µ .\n",
            "\n",
            "uk: –í—ñ–Ω —à–≤–∏–¥–∫–æ –≤—Ç–æ–º–ª—é—î—Ç—å—Å—è.\n",
            "ru: –û–Ω –±—ã—Å—Ç—Ä–æ —É—Å—Ç–∞–µ—Ç .\n",
            "\n",
            "uk: –£—Å—ñ –≥–æ—Ç–æ–≤—ñ.\n",
            "ru: –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≥–æ—Ç–æ–≤—ã .\n",
            "\n",
            "uk: –í—ñ–Ω —Å–∫—É—á–∞—î –ø–æ —Å–≤–æ—ó–π —Å—ñ–º'—ó.\n",
            "ru: –û–Ω —Å–∫—É—á–∞–µ—Ç –ø–æ —Å–≤–æ–µ–π —Å–µ–º—å —Å–æ –º—å–µ .\n",
            "\n",
            "uk: ¬´–î—è–∫—É—é¬ª, ‚Äî ¬´–ù–∞ –∑–¥–æ—Ä–æ–≤'—è¬ª.\n",
            "ru: ¬´ –°–ø–∞—Å–∏–±–æ UNK ‚Äî ¬´ –ø–æ –∑–¥–æ—Ä–æ–≤—å–µ —Å–æ –º–Ω–æ–π UNK\n",
            "\n",
            "uk: –Ø —â–µ –Ω–µ –∑–Ω–∞—é —Å–≤–æ—î—ó –∞–¥—Ä–µ—Å–∏, —è –ø–µ–≤–Ω–∏–π —á–∞—Å –±—É–¥—É –∂–∏—Ç–∏ –≤ –ø–æ–¥—Ä—É–≥–∏.\n",
            "ru: –Ø –µ—âe –Ω–µ –∑–Ω–∞—é —Å–≤–æ–µ–≥–æ –∞–¥—Ä–µ—Å–∞ , –º–Ω–æ–π –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –±—É–¥—É –∂–∏—Ç—å –≤–æ –ø–æ–¥—Ä—É–≥–∏ .\n",
            "\n",
            "uk: –ê–º–∞–∑–æ–Ω–∫–∞‚Äî –¥—Ä—É–≥–∞ –ø–æ –¥–æ–≤–∂–∏–Ω—ñ —Ä—ñ–∫–∞ –≤ —Å–≤—ñ—Ç—ñ –ø—ñ—Å–ª—è –ù—ñ–ª–∞.\n",
            "ru: –ê–º–∞–∑–æ–Ω–∫–∞ ‚Äî –≤—Ç–æ—Ä–∞—è –ø–æ –¥–ª–∏–Ω–µ —Ä–µ–∫–∞ –≤–æ –º–∏—Ä–µ –ø–æ—Å–ª–µ –ù–∏–ª–∞ .\n",
            "\n",
            "uk: –ê —è–∫—â–æ –ø–æ–±–∞—á–∏—à –¢–æ–º–∞, –ø–µ—Ä–µ–¥–∞–π –π–æ–º—É –≤—ñ–¥ –º–µ–Ω–µ –≤—ñ—Ç–∞–Ω–Ω—è.\n",
            "ru: –ê –µ—Å–ª–∏ —É–≤–∏–¥–∏—à—å –¢–∏–º–∞ , –ø–µ—Ä–µ–¥–∞–π –µ–º—É –æ—Ç –º–µ–Ω—è –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏—è .\n",
            "\n",
            "uk: –ó–∞–∫—Ä–∏–π –∑–∞ —Å–æ–±–æ—é –¥–≤–µ—Ä—ñ.\n",
            "ru: –∑–∞–∫—Ä–æ–π –∑–∞ —Å–æ–±–æ–π –¥–≤–µ—Ä—å .\n",
            "\n",
            "uk: –¢—Ä–∏–º–∞–π –ø—Ä–∏ —Å–æ–±—ñ —Å–ª–æ–≤–Ω–∏–∫.\n",
            "ru: –î–µ—Ä–∂–∏ –ø—Ä–∏ —Å–µ–±–µ —Å–ª–æ–≤–∞—Ä—å .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for sent in uk_corpus[::10]:\n",
        "    print('uk: {}'.format(sent), end='')\n",
        "    print('ru: {}'.format(translate(sent)), end='\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXMxWUtipDD8"
      },
      "source": [
        "Great! \n",
        "See second notebook for the Neural Machine Translation assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='darkviolet'><i> \n",
        "‚úèÔ∏è –í —ç—Ç–æ–π –ª–∞–±–µ –≤—Ç–æ—Ä–æ–π –Ω–æ—É—Ç–±—É–∫ –Ω–∞–º –Ω–µ –≤—ã–¥–∞–ª–∏.\n",
        "</i></font>"
      ],
      "metadata": {
        "id": "8CM8u_ankomk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jyCVbgniktoU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "made_nlp_Lab1_part1_Embedding_based_MT.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}